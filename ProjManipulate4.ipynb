{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import gensim\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.externals import joblib\n",
    "import csv\n",
    "import tweepy\n",
    "import cnfg\n",
    "import datetime\n",
    "import quandl\n",
    "import matplotlib.pyplot as plt\n",
    "quandl.ApiConfig.api_key = '***************' \n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "# pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sandp100 = ['AAPL','ABBV','ABT','ACN','AGN','AIG','ALL','AMGN','AMZN','AXP','BA','BAC',\n",
    "            'BIIB','BK','BLK','BMY','BRK.B','C','CAT','CELG','CL','CMCSA','COF','COP',\n",
    "            'COST','CSCO','CVS','CVX','DD','DHR','DIS','DOW','DUK','EMR','EXC','F','FB',\n",
    "            'FDX','FOX','FOXA','GD','GE','GILD','GM','GOOG','GOOGL','GS','HAL','HD','HON',\n",
    "            'IBM','INTC','JNJ','JPM','KHC','KMI','KO','LLY','LMT','LOW','MA','MCD','MDLZ',\n",
    "            'MDT','MET','MMM','MO','MON','MRK','MS','MSFT','NEE','NKE','ORCL','OXY','PCLN',\n",
    "            'PEP','PFE','PG','PM','PYPL','QCOM','RTN','SBUX','SLB','SO','SPG','T','TGT',\n",
    "            'TWX','TXN','UNH','UNP','UPS','USB','UTX','V','VZ','WBA','WFC','WMT','XOM']\n",
    "\n",
    "sandp100find = [\"XX'AAPL\",\"XX'ABBV\",\"XX'ABT\",\"XX'ACN\",\"XX'AGN\",\"XX'AIG\",\"XX'ALL\",\"XX'AMGN\",\n",
    "                \"XX'AMZN\",\"XX'AXP\",\"XX'BA\",\"XX'BAC\",\"XX'BIIB\",\"XX'BK\",\"XX'BLK\",\"XX'BMY\",\n",
    "                \"XX'BRK.B\",\"XX'C\",\"XX'CAT\",\"XX'CELG\",\"XX'CL\",\"XX'CMCSA\",\"XX'COF\",\"XX'COP\",\n",
    "                \"XX'COST\",\"XX'CSCO\",\"XX'CVS\",\"XX'CVX\",\"XX'DD\",\"XX'DHR\",\"XX'DIS\",\"XX'DOW\",\n",
    "                \"XX'DUK\",\"XX'EMR\",\"XX'EXC\",\"XX'F\",\"XX'FB\",\"XX'FDX\",\"XX'FOX\",\"XX'FOXA\",\"XX'GD\",\n",
    "                \"XX'GE\",\"XX'GILD\",\"XX'GM\",\"XX'GOOG\",\"XX'GOOGL\",\"XX'GS\",\"XX'HAL\",\"XX'HD\",\"XX'HON\",\n",
    "                \"XX'IBM\",\"XX'INTC\",\"XX'JNJ\",\"XX'JPM\",\"XX'KHC\",\"XX'KMI\",\"XX'KO\",\"XX'LLY\",\"XX'LMT\",\n",
    "                \"XX'LOW\",\"XX'MA\",\"XX'MCD\",\"XX'MDLZ\",\"XX'MDT\",\"XX'MET\",\"XX'MMM\",\"XX'MO\",\"XX'MON\",\n",
    "                \"XX'MRK\",\"XX'MS\",\"XX'MSFT\",\"XX'NEE\",\"XX'NKE\",\"XX'ORCL\",\"XX'OXY\",\"XX'PCLN\",\"XX'PEP\",\n",
    "                \"XX'PFE\",\"XX'PG\",\"XX'PM\",\"XX'PYPL\",\"XX'QCOM\",\"XX'RTN\",\"XX'SBUX\",\"XX'SLB\",\"XX'SO\",\n",
    "                \"XX'SPG\",\"XX'T\",\"XX'TGT\",\"XX'TWX\",\"XX'TXN\",\"XX'UNH\",\"XX'UNP\",\"XX'UPS\",\"XX'USB\",\n",
    "                \"XX'UTX\",\"XX'V\",\"XX'VZ\",\"XX'WBA\",\"XX'WFC\",\"XX'WMT\",\"XX'XOM\"]\n",
    "\n",
    "sandp100lower = [element.lower() for element in sandp100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_quan = pd.read_csv('WIKI_PRICES_1ef64a24111c5bc7e6a0a66f6e37080e.csv')\n",
    "quanstocklist = list(stock_quan.ticker.unique())\n",
    "quanstocklist.remove('AA')\n",
    "quanstocklist.remove('ANF')\n",
    "quanstocklist.remove('AMD')\n",
    "quanstocklist.remove('FOSL')\n",
    "quanstocklist.remove('TASR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "\n",
    "df = DataFrame(list(db.stocks.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icahn = DataFrame(list(db.icahn.find({})))\n",
    "icahn['user'] = 'icahn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(icahn['text'])):\n",
    "    list1.append(icahn['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(icahn['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "icahn['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icahn = icahn[icahn['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "# icahn = icahn[icahn['cleanedtext'].str.contains(\"AAPL|ABBV|ABT|ACN|AGN|AIG|ALL|AMGN|AMZN|AXP|BA|BAC|BIIB|BK|BLK|BMY|BRK.B|C|CAT|CELG|CL|CMCSA|COF|COP|COST|CSCO|CVS|CVX|DD|DHR|DIS|DOW|DUK|EMR|EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=False)]\n",
    "icahn = icahn[icahn['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icahn['date'] = icahn['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "icahn = icahn.sort_values(by='date')\n",
    "icahnextract = icahn.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "icahnextract = icahnextract.unstack()\n",
    "icahn = icahn.join(icahnextract)\n",
    "icahn = icahn.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(8, icahn.shape[1]):\n",
    "    icahn.iloc[:,i] = icahn.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icahn = icahn[(icahn['date']>datetime.date(2010,9,12)) & (icahn['date']<datetime.date(2017,5,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = (analyser.polarity_scores(sentence)['compound'])\n",
    "    return snt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listicahn = []\n",
    "for i in icahn.cleanedtext:\n",
    "    listicahn.append(print_sentiment_scores(i))\n",
    "\n",
    "se3 = pd.Series(listicahn)\n",
    "icahn['compound'] = se3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icahn = icahn[icahn['compound'] > 0.0]\n",
    "icahn.drop(['compound'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_to_api(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(icahn.iloc[:,7], icahn.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "            first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "    final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(link_to_api(8))\n",
    "icahn['return_one_portfolio'] = se.values\n",
    "icahn['return_one_portfolio'] = pd.to_numeric(icahn['return_one_portfolio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(icahn.iloc[:,7], icahn.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "icahn['return_one'] = se.values\n",
    "icahn['return_one'] = pd.to_numeric(icahn['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(icahn.iloc[:,7], icahn.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "icahn['volatility'] = se.values\n",
    "icahn['volatility'] = pd.to_numeric(icahn['volatility'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_momentum(X):\n",
    "    count = 0\n",
    "    open_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(icahn.iloc[:,7], icahn.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            open_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            open_list.append(my_data.iloc[0,0])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    open_list = list(map(float, open_list))\n",
    "    close_list = list(map(float,close_list))\n",
    "    final_list = [np.log(z/x) for x,z in zip(open_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "# np.log(closes/opens)\n",
    "    \n",
    "se = pd.Series(calc_momentum(8))\n",
    "icahn['momentum'] = se.values\n",
    "icahn['momentum'] = pd.to_numeric(icahn['momentum'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0825901114473022"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Portfolio Sharpe\n",
    "(icahn['return_one_portfolio'].mean() - .00109)/(icahn['return_one_portfolio'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.796824719082593"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single Average Sharpe Ratio\n",
    "(icahn['return_one'].mean() - .00109)/(icahn['return_one'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PETER W**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peterw = DataFrame(list(db.peterw.find({})))\n",
    "peterw['user'] = 'peterw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(peterw['text'])):\n",
    "    list1.append(peterw['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(peterw['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "peterw['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "peterw = peterw[peterw['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "peterw = peterw[peterw['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "\n",
    "peterw['date'] = peterw['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "peterw = peterw.sort_values(by='date')\n",
    "peterwextract = peterw.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "peterwextract = peterwextract.unstack()\n",
    "peterw = peterw.join(peterwextract)\n",
    "peterw = peterw.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, peterw.shape[1]):\n",
    "    peterw.iloc[:,i] = peterw.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peterw = peterw[(peterw['date']>datetime.date(2010,9,12)) & (peterw['date']<datetime.date(2017,5,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = (analyser.polarity_scores(sentence)['compound'])\n",
    "    return snt\n",
    "\n",
    "\n",
    "listpeterw = []\n",
    "for i in peterw.cleanedtext:\n",
    "    listpeterw.append(print_sentiment_scores(i))\n",
    "\n",
    "se3 = pd.Series(listpeterw)\n",
    "peterw['compound'] = se3.values\n",
    "\n",
    "\n",
    "peterw = peterw[peterw['compound'] > 0.1]\n",
    "peterw.drop(['compound'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peterw = peterw[peterw.iloc[:,8] != 'UA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_to_api(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(peterw.iloc[:,7], peterw.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "            first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "    final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(link_to_api(8))\n",
    "peterw['return_one_portfolio'] = se.values\n",
    "peterw['return_one_portfolio'] = pd.to_numeric(peterw['return_one_portfolio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(peterw.iloc[:,7], peterw.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "peterw['return_one'] = se.values\n",
    "peterw['return_one'] = pd.to_numeric(peterw['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(peterw.iloc[:,7], peterw.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "peterw['volatility'] = se.values\n",
    "peterw['volatility'] = pd.to_numeric(peterw['volatility'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_momentum(X):\n",
    "    count = 0\n",
    "    open_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(peterw.iloc[:,7], peterw.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            open_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            open_list.append(my_data.iloc[0,0])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    open_list = list(map(float, open_list))\n",
    "    close_list = list(map(float,close_list))\n",
    "    final_list = [np.log(z/x) for x,z in zip(open_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "# np.log(closes/opens)\n",
    "    \n",
    "se = pd.Series(calc_momentum(8))\n",
    "peterw['momentum'] = se.values\n",
    "peterw['momentum'] = pd.to_numeric(peterw['momentum'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3961502195272659"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Portfolio Sharpe\n",
    "(peterw['return_one_portfolio'].mean() - .00109)/(peterw['return_one_portfolio'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1953741659892203"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single Average Sharpe Ratio\n",
    "(peterw['return_one'].mean() - .00109)/(peterw['return_one'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERGEN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bergencapital = DataFrame(list(db.bergencapital.find({})))\n",
    "bergencapital['user'] = 'bergencapital'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(bergencapital['text'])):\n",
    "    list1.append(bergencapital['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(bergencapital['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "bergencapital['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "bergencapital = bergencapital[bergencapital['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "bergencapital = bergencapital[bergencapital['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "\n",
    "bergencapital['date'] = bergencapital['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "bergencapital = bergencapital.sort_values(by='date')\n",
    "bergencapitalextract = bergencapital.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "bergencapitalextract = bergencapitalextract.unstack()\n",
    "bergencapital = bergencapital.join(bergencapitalextract)\n",
    "bergencapital = bergencapital.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, bergencapital.shape[1]):\n",
    "    bergencapital.iloc[:,i] = bergencapital.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bergencapital = bergencapital[(bergencapital['date']>datetime.date(2010,9,12)) & (bergencapital['date']<datetime.date(2017,5,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = (analyser.polarity_scores(sentence)['compound'])\n",
    "    return snt\n",
    "\n",
    "\n",
    "listbergencapital = []\n",
    "for i in bergencapital.cleanedtext:\n",
    "    listbergencapital.append(print_sentiment_scores(i))\n",
    "\n",
    "se3 = pd.Series(listbergencapital)\n",
    "bergencapital['compound'] = se3.values\n",
    "\n",
    "\n",
    "bergencapital = bergencapital[bergencapital['compound'] > 0.2]\n",
    "bergencapital.drop(['compound'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_to_api(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(bergencapital.iloc[:,7], bergencapital.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "            first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "    final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(link_to_api(8))\n",
    "bergencapital['return_one_portfolio'] = se.values\n",
    "bergencapital['return_one_portfolio'] = pd.to_numeric(bergencapital['return_one_portfolio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(bergencapital.iloc[:,7], bergencapital.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "bergencapital['return_one'] = se.values\n",
    "bergencapital['return_one'] = pd.to_numeric(bergencapital['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(bergencapital.iloc[:,7], bergencapital.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "bergencapital['volatility'] = se.values\n",
    "bergencapital['volatility'] = pd.to_numeric(bergencapital['volatility'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_momentum(X):\n",
    "    count = 0\n",
    "    open_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(bergencapital.iloc[:,7], bergencapital.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            open_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            open_list.append(my_data.iloc[0,0])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    open_list = list(map(float, open_list))\n",
    "    close_list = list(map(float,close_list))\n",
    "    final_list = [np.log(z/x) for x,z in zip(open_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "# np.log(closes/opens)\n",
    "    \n",
    "se = pd.Series(calc_momentum(8))\n",
    "bergencapital['momentum'] = se.values\n",
    "bergencapital['momentum'] = pd.to_numeric(bergencapital['momentum'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988352976772682"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Portfolio Sharpe\n",
    "(bergencapital['return_one_portfolio'].mean() - .00109)/(bergencapital['return_one_portfolio'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8159003038721571"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single Average Sharpe Ratio\n",
    "(bergencapital['return_one'].mean() - .00109)/(bergencapital['return_one'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdow = DataFrame(list(db.markdow.find({})))\n",
    "markdow['user'] = 'markdow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(markdow['text'])):\n",
    "    list1.append(markdow['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(markdow['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "markdow['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "markdow = markdow[markdow['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "markdow = markdow[markdow['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "\n",
    "markdow['date'] = markdow['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "markdow = markdow.sort_values(by='date')\n",
    "markdowextract = markdow.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "markdowextract = markdowextract.unstack()\n",
    "markdow = markdow.join(markdowextract)\n",
    "markdow = markdow.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, markdow.shape[1]):\n",
    "    markdow.iloc[:,i] = markdow.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdow = markdow[(markdow['date']>datetime.date(2010,9,12)) & (markdow['date']<datetime.date(2017,5,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = (analyser.polarity_scores(sentence)['compound'])\n",
    "    return snt\n",
    "\n",
    "\n",
    "listmarkdow = []\n",
    "for i in markdow.cleanedtext:\n",
    "    listmarkdow.append(print_sentiment_scores(i))\n",
    "\n",
    "se3 = pd.Series(listmarkdow)\n",
    "markdow['compound'] = se3.values\n",
    "\n",
    "\n",
    "markdow = markdow[markdow['compound'] > 0.1]\n",
    "markdow.drop(['compound'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_to_api(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(markdow.iloc[:,7], markdow.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "            first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "    final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(link_to_api(8))\n",
    "markdow['return_one_portfolio'] = se.values\n",
    "markdow['return_one_portfolio'] = pd.to_numeric(markdow['return_one_portfolio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(markdow.iloc[:,7], markdow.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "markdow['return_one'] = se.values\n",
    "markdow['return_one'] = pd.to_numeric(markdow['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(markdow.iloc[:,7], markdow.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "markdow['volatility'] = se.values\n",
    "markdow['volatility'] = pd.to_numeric(markdow['volatility'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_momentum(X):\n",
    "    count = 0\n",
    "    open_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(markdow.iloc[:,7], markdow.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            open_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            open_list.append(my_data.iloc[0,0])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    open_list = list(map(float, open_list))\n",
    "    close_list = list(map(float,close_list))\n",
    "    final_list = [np.log(z/x) for x,z in zip(open_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "# np.log(closes/opens)\n",
    "    \n",
    "se = pd.Series(calc_momentum(8))\n",
    "markdow['momentum'] = se.values\n",
    "markdow['momentum'] = pd.to_numeric(markdow['momentum'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1517300333443612"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Portfolio Sharpe\n",
    "(markdow['return_one_portfolio'].mean() - .00109)/(markdow['return_one_portfolio'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0347208827963912"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single Average Sharpe Ratio\n",
    "(markdow['return_one'].mean() - .00109)/(markdow['return_one'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lexvandam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexvandam = DataFrame(list(db.lexvandam.find({})))\n",
    "lexvandam['user'] = 'lexvandam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(lexvandam['text'])):\n",
    "    list1.append(lexvandam['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(lexvandam['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "lexvandam['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "lexvandam = lexvandam[lexvandam['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "lexvandam = lexvandam[lexvandam['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "\n",
    "lexvandam['date'] = lexvandam['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "lexvandam = lexvandam.sort_values(by='date')\n",
    "lexvandamextract = lexvandam.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "lexvandamextract = lexvandamextract.unstack()\n",
    "lexvandam = lexvandam.join(lexvandamextract)\n",
    "lexvandam = lexvandam.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, lexvandam.shape[1]):\n",
    "    lexvandam.iloc[:,i] = lexvandam.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexvandam = lexvandam[(lexvandam['date']>datetime.date(2010,9,12)) & (lexvandam['date']<datetime.date(2017,5,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = (analyser.polarity_scores(sentence)['compound'])\n",
    "    return snt\n",
    "\n",
    "\n",
    "listlexvandam = []\n",
    "for i in lexvandam.cleanedtext:\n",
    "    listlexvandam.append(print_sentiment_scores(i))\n",
    "\n",
    "se3 = pd.Series(listlexvandam)\n",
    "lexvandam['compound'] = se3.values\n",
    "\n",
    "\n",
    "lexvandam = lexvandam[lexvandam['compound'] > 0.1]\n",
    "lexvandam.drop(['compound'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_to_api(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(lexvandam.iloc[:,7], lexvandam.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "            first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "    final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(link_to_api(8))\n",
    "lexvandam['return_one_portfolio'] = se.values\n",
    "lexvandam['return_one_portfolio'] = pd.to_numeric(lexvandam['return_one_portfolio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(lexvandam.iloc[:,7], lexvandam.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "lexvandam['return_one'] = se.values\n",
    "lexvandam['return_one'] = pd.to_numeric(lexvandam['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(lexvandam.iloc[:,7], lexvandam.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "lexvandam['volatility'] = se.values\n",
    "lexvandam['volatility'] = pd.to_numeric(lexvandam['volatility'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_momentum(X):\n",
    "    count = 0\n",
    "    open_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(lexvandam.iloc[:,7], lexvandam.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            open_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            open_list.append(my_data.iloc[0,0])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    open_list = list(map(float, open_list))\n",
    "    close_list = list(map(float,close_list))\n",
    "    final_list = [np.log(z/x) for x,z in zip(open_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "# np.log(closes/opens)\n",
    "    \n",
    "se = pd.Series(calc_momentum(8))\n",
    "lexvandam['momentum'] = se.values\n",
    "lexvandam['momentum'] = pd.to_numeric(lexvandam['momentum'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5855521886423283"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Portfolio Sharpe\n",
    "(lexvandam['return_one_portfolio'].mean() - .00109)/(lexvandam['return_one_portfolio'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9016977983817664"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single Average Sharpe Ratio\n",
    "(lexvandam['return_one'].mean() - .00109)/(lexvandam['return_one'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**timseymour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timseymour = DataFrame(list(db.timseymour.find({})))\n",
    "timseymour['user'] = 'timseymour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(timseymour['text'])):\n",
    "    list1.append(timseymour['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(timseymour['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "timseymour['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "timseymour = timseymour[timseymour['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "timseymour = timseymour[timseymour['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "\n",
    "timseymour['date'] = timseymour['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "timseymour = timseymour.sort_values(by='date')\n",
    "timseymourextract = timseymour.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "timseymourextract = timseymourextract.unstack()\n",
    "timseymour = timseymour.join(timseymourextract)\n",
    "timseymour = timseymour.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, timseymour.shape[1]):\n",
    "    timseymour.iloc[:,i] = timseymour.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timseymour = timseymour[(timseymour['date']>datetime.date(2010,9,12)) & (timseymour['date']<datetime.date(2017,5,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = (analyser.polarity_scores(sentence)['compound'])\n",
    "    return snt\n",
    "\n",
    "\n",
    "listtimseymour = []\n",
    "for i in timseymour.cleanedtext:\n",
    "    listtimseymour.append(print_sentiment_scores(i))\n",
    "\n",
    "se3 = pd.Series(listtimseymour)\n",
    "timseymour['compound'] = se3.values\n",
    "\n",
    "\n",
    "timseymour = timseymour[timseymour['compound'] > 0.1]\n",
    "timseymour.drop(['compound'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_to_api(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(timseymour.iloc[:,7], timseymour.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "            first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "    final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(link_to_api(8))\n",
    "timseymour['return_one_portfolio'] = se.values\n",
    "timseymour['return_one_portfolio'] = pd.to_numeric(timseymour['return_one_portfolio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(timseymour.iloc[:,7], timseymour.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "timseymour['return_one'] = se.values\n",
    "timseymour['return_one'] = pd.to_numeric(timseymour['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(timseymour.iloc[:,7], timseymour.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "timseymour['volatility'] = se.values\n",
    "timseymour['volatility'] = pd.to_numeric(timseymour['volatility'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_momentum(X):\n",
    "    count = 0\n",
    "    open_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(timseymour.iloc[:,7], timseymour.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            open_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            open_list.append(my_data.iloc[0,0])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    open_list = list(map(float, open_list))\n",
    "    close_list = list(map(float,close_list))\n",
    "    final_list = [np.log(z/x) for x,z in zip(open_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "# np.log(closes/opens)\n",
    "    \n",
    "se = pd.Series(calc_momentum(8))\n",
    "timseymour['momentum'] = se.values\n",
    "timseymour['momentum'] = pd.to_numeric(timseymour['momentum'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.9145024506312494"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Portfolio Sharpe\n",
    "(timseymour['return_one_portfolio'].mean() - .00109)/(timseymour['return_one_portfolio'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.6654432703042374"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single Average Sharpe Ratio\n",
    "(timseymour['return_one'].mean() - .00109)/(timseymour['return_one'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GECKOJB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojb = DataFrame(list(db.geckojb.find({})))\n",
    "geckojb['user'] = 'geckojb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(geckojb['text'])):\n",
    "    list1.append(geckojb['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(geckojb['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "geckojb['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "geckojb = geckojb[geckojb['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "geckojb = geckojb[geckojb['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "\n",
    "geckojb['date'] = geckojb['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "geckojb = geckojb.sort_values(by='date')\n",
    "geckojbextract = geckojb.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "geckojbextract = geckojbextract.unstack()\n",
    "geckojb = geckojb.join(geckojbextract)\n",
    "geckojb = geckojb.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, geckojb.shape[1]):\n",
    "    geckojb.iloc[:,i] = geckojb.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojb = geckojb[(geckojb['date']>datetime.date(2010,9,12)) & (geckojb['date']<datetime.date(2017,5,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = (analyser.polarity_scores(sentence)['compound'])\n",
    "    return snt\n",
    "\n",
    "\n",
    "listgeckojb = []\n",
    "for i in geckojb.cleanedtext:\n",
    "    listgeckojb.append(print_sentiment_scores(i))\n",
    "\n",
    "se3 = pd.Series(listgeckojb)\n",
    "geckojb['compound'] = se3.values\n",
    "\n",
    "\n",
    "geckojb = geckojb[geckojb['compound'] > 0.1]\n",
    "geckojb.drop(['compound'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojb = geckojb[geckojb.iloc[:,8] != 'COMPQ']\n",
    "geckojb = geckojb[geckojb.iloc[:,8] != 'GOOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_to_api(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(geckojb.iloc[:,7], geckojb.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "            first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "#         print(enum_list)\n",
    "    first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "    final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(link_to_api(8))\n",
    "geckojb['return_one_portfolio'] = se.values\n",
    "geckojb['return_one_portfolio'] = pd.to_numeric(geckojb['return_one_portfolio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(geckojb.iloc[:,7], geckojb.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "geckojb['return_one'] = se.values\n",
    "geckojb['return_one'] = pd.to_numeric(geckojb['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(geckojb.iloc[:,7], geckojb.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "geckojb['volatility'] = se.values\n",
    "geckojb['volatility'] = pd.to_numeric(geckojb['volatility'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_momentum(X):\n",
    "    count = 0\n",
    "    open_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(geckojb.iloc[:,7], geckojb.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            open_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            open_list.append(my_data.iloc[0,0])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    open_list = list(map(float, open_list))\n",
    "    close_list = list(map(float,close_list))\n",
    "    final_list = [np.log(z/x) for x,z in zip(open_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "# np.log(closes/opens)\n",
    "    \n",
    "se = pd.Series(calc_momentum(8))\n",
    "geckojb['momentum'] = se.values\n",
    "geckojb['momentum'] = pd.to_numeric(geckojb['momentum'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.588397180625905"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Portfolio Sharpe\n",
    "(geckojb['return_one_portfolio'].mean() - .00109)/(geckojb['return_one_portfolio'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5577296888059582"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single Average Sharpe Ratio\n",
    "(geckojb['return_one'].mean() - .00109)/(geckojb['return_one'].std()) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manipulate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finviz = pd.read_csv('finviz.csv')\n",
    "finviz1 = finviz.iloc[:,[1,3,4,5]]\n",
    "icahn10 = icahn.iloc[:,[5,8,10,11,12]]\n",
    "peterw10 = peterw.iloc[:,[5,8,14,15,16]]\n",
    "bergencapital10 = bergencapital.iloc[:,[5,8,14,15,16]]\n",
    "# markdow10 = markdow.iloc[:,[5,8,10,11,12]]\n",
    "lexvandam10 = lexvandam.iloc[:,[5,8,15,16,17]]\n",
    "timseymour10 = timseymour.iloc[:,[5,8,14,15,16]]\n",
    "# geckojb10 = geckojb.iloc[:,[5,8,28,29,30]]\n",
    "\n",
    "\n",
    "\n",
    "newdf=icahn10.append(peterw10)\n",
    "newdf=newdf.append(bergencapital10)\n",
    "# newdf=newdf.append(markdow10)\n",
    "newdf = newdf.append(lexvandam10)\n",
    "# newdf = newdf.append(timseymour10) ##AFTER MARKET PASSED\n",
    "# newdf = newdf.append(geckojb10)\n",
    "\n",
    "\n",
    "\n",
    "column_names = ['user', 'Ticker', 'return_one_portfolio', 'return_one', 'volatility']\n",
    "newdf.columns = column_names\n",
    "newdf = newdf.merge(finviz1, on='Ticker', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newdf[(newdf['user'] == 'icahn') & (newdf['Ticker'] == 'AAPL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf = newdf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "def onehotencode(column_name):\n",
    "    global newdf\n",
    "    st = patsy.dmatrix(column_name,\n",
    "                     data=newdf,\n",
    "                     return_type='dataframe')\n",
    "    newdf.drop([column_name], axis=1, inplace=True)\n",
    "    newdf = newdf.join(st)\n",
    "    newdf.drop(['Intercept'], axis=1, inplace=True)\n",
    "    return newdf\n",
    "\n",
    "newdf = onehotencode('Sector')\n",
    "newdf = onehotencode('Industry')\n",
    "newdf = onehotencode('Country')\n",
    "newdf = onehotencode('Ticker')\n",
    "newdf = onehotencode('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf.columns = newdf.columns.map(lambda x: x.replace('[', '_'))\n",
    "newdf.columns = newdf.columns.map(lambda x: x.replace(']', ''))\n",
    "newdf.columns = newdf.columns.map(lambda x: x.replace('.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_target= newdf.iloc[:,1]\n",
    "newdf.drop(['return_one'], axis=1, inplace=True)\n",
    "newdf.drop(['return_one_portfolio'], axis=1, inplace=True)\n",
    "X_data = newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# The train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_target, \n",
    "                                                    test_size=.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgboost.XGBRegressor(objective = \"reg:linear\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_data)\n",
    "\n",
    "gbm_params = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [300, 1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypred2 = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.506161711562\n",
      "MSE: 0.026203068661\n"
     ]
    }
   ],
   "source": [
    "print('Test:',model.score(X_test, y_test))\n",
    "print ('MSE:', np.sqrt(metrics.mean_squared_error(y_test, ypred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.1, 0.1)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAGECAYAAABUEnu5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158f21d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(y_test, ypred2,'ro');\n",
    "ax.set_xlabel('Actual Return')\n",
    "ax.set_ylabel('Predicted Return')\n",
    "plt.title('Predicted vs Actual')\n",
    "\n",
    "ax.set_xlim(-0.1, 0.1)\n",
    "ax.set_ylim(-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.newstocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bergencapitalnew = DataFrame(list(db.bergencapital2.find({})))\n",
    "bergencapitalnew['user'] = 'Mike Bergen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(bergencapitalnew['text'])):\n",
    "    list1.append(bergencapitalnew['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(bergencapitalnew['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "bergencapitalnew['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "bergencapitalnew = bergencapitalnew[bergencapitalnew['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "bergencapitalnew = bergencapitalnew[bergencapitalnew['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "# bergencapitalnew[bergencapitalnew.text.str.contains('|'.join(sandp100find))]\n",
    "\n",
    "bergencapitalnew['date'] = bergencapitalnew['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "bergencapitalnew = bergencapitalnew.sort_values(by='date')\n",
    "bergencapitalnewextract = bergencapitalnew.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "bergencapitalnewextract = bergencapitalnewextract.unstack()\n",
    "bergencapitalnew = bergencapitalnew.join(bergencapitalnewextract)\n",
    "bergencapitalnew = bergencapitalnew.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, bergencapitalnew.shape[1]):\n",
    "    bergencapitalnew.iloc[:,i] = bergencapitalnew.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bergencapitalnew = bergencapitalnew[(bergencapitalnew['date']>datetime.date(2017,5,1)) & (bergencapitalnew['date']<datetime.date(2017,6,18))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# def print_sentiment_scores(sentence):\n",
    "#     snt = (analyser.polarity_scores(sentence)['compound'])\n",
    "#     return snt\n",
    "\n",
    "\n",
    "# listbergencapitalnew = []\n",
    "# for i in bergencapitalnew.cleanedtext:\n",
    "#     listbergencapitalnew.append(print_sentiment_scores(i))\n",
    "\n",
    "# se3 = pd.Series(listbergencapitalnew)\n",
    "# bergencapitalnew['compound'] = se3.values\n",
    "\n",
    "\n",
    "# bergencapitalnew = bergencapitalnew[bergencapitalnew['compound'] > 0.0]\n",
    "# bergencapitalnew.drop(['compound'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 14)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bergencapitalnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_to_api(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(bergencapitalnew.iloc[:,7], bergencapitalnew.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "            first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "    final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(link_to_api(8))\n",
    "bergencapitalnew['return_one_portfolio'] = se.values\n",
    "bergencapitalnew['return_one_portfolio'] = pd.to_numeric(bergencapitalnew['return_one_portfolio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(bergencapitalnew.iloc[:,7], bergencapitalnew.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,3] - my_data.iloc[0,3])/my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "bergencapitalnew['return_one'] = se.values\n",
    "bergencapitalnew['return_one'] = pd.to_numeric(bergencapitalnew['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(bergencapitalnew.iloc[:,7], bergencapitalnew.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "bergencapitalnew['volatility'] = se.values\n",
    "bergencapitalnew['volatility'] = pd.to_numeric(bergencapitalnew['volatility'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MARKDOW UPDATE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdownew = DataFrame(list(db.markdownew.find({})))\n",
    "markdownew['user'] = 'Mark Dow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(markdownew['text'])):\n",
    "    list1.append(markdownew['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(markdownew['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "markdownew['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "markdownew = markdownew[markdownew['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "markdownew = markdownew[markdownew['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "# bergencapitalnew[bergencapitalnew.text.str.contains('|'.join(sandp100find))]\n",
    "\n",
    "markdownew['date'] = markdownew['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "markdownew = markdownew.sort_values(by='date')\n",
    "markdownewextract = markdownew.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "markdownewextract = markdownewextract.unstack()\n",
    "markdownew = markdownew.join(markdownewextract)\n",
    "markdownew = markdownew.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, markdownew.shape[1]):\n",
    "    markdownew.iloc[:,i] = markdownew.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdownew = markdownew[(markdownew['date']>datetime.date(2017,5,1)) & (markdownew['date']<datetime.date(2017,6,18))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdownew = markdownew[markdownew.iloc[:,8] != 'FSLR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(markdownew.iloc[:,7], markdownew.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,10] - my_data.iloc[0,10])/my_data.iloc[0,10])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "markdownew['return_one'] = se.values\n",
    "markdownew['return_one'] = pd.to_numeric(markdownew['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# amzndf.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(markdownew.iloc[:,7], markdownew.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(8))\n",
    "markdownew['prev_day_volatility'] = se.values\n",
    "markdownew['prev_day_volatility'] = pd.to_numeric(markdownew['prev_day_volatility'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdownew10 = markdownew.iloc[:,[5,8,10,11]]\n",
    "\n",
    "markdownew10 = markdownew10.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "column_names = ['user', 'Ticker', 'return_one', 'volatility']\n",
    "markdownew10.columns = column_names\n",
    "newdfnew = markdownew10.merge(finviz1, on='Ticker', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "def onehotencode(column_name):\n",
    "    global newdfnew\n",
    "    st = patsy.dmatrix(column_name,\n",
    "                     data=newdfnew,\n",
    "                     return_type='dataframe')\n",
    "    newdfnew.drop([column_name], axis=1, inplace=True)\n",
    "    newdfnew = newdfnew.join(st)\n",
    "    newdfnew.drop(['Intercept'], axis=1, inplace=True)\n",
    "    return newdfnew\n",
    "\n",
    "newdfnew = onehotencode('Sector')\n",
    "newdfnew = onehotencode('Industry')\n",
    "newdfnew = onehotencode('Country')\n",
    "newdfnew = onehotencode('Ticker')\n",
    "newdfnew = onehotencode('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdfnew.columns = newdfnew.columns.map(lambda x: x.replace('[', '_'))\n",
    "newdfnew.columns = newdfnew.columns.map(lambda x: x.replace(']', ''))\n",
    "newdfnew.columns = newdfnew.columns.map(lambda x: x.replace('.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_target2= newdfnew.iloc[:,1]\n",
    "newdfnew.drop(['return_one'], axis=1, inplace=True)\n",
    "X_data2 = newdfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdata3 = pd.merge(X_data2, X_data, how='outer')\n",
    "\n",
    "xdata3 = xdata3.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdata3 = xdata3.iloc[[1,2],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list3 = model._Booster.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdata3 = xdata3[list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model._Booster.dump_model('dump.raw.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdownpredict = model.predict(xdata3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdownewfinal=markdownew.iloc[:,[7,4,5,8,10]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdownewfinal['prediction'] = markdownpredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names2 = ['Date', 'Tweet', 'User','Tiker' 'Actual_Return', 'Prediction']\n",
    "markdownewfinal.columns = column_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdownewfinal.to_csv('markdownewfinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check = pd.read_csv('markdownewfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GECKOJB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojbnew = DataFrame(list(db.geckojbnew.find({})))\n",
    "geckojbnew['user'] = 'John Benedict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(geckojbnew['text'])):\n",
    "    list1.append(geckojbnew['text'].str.split(' http')[i][0])\n",
    "    \n",
    "se = pd.Series(list1)\n",
    "se = se.str.replace('b\"', \"b'\")\n",
    "se = se.str.replace('$', \"XX'\")\n",
    "\n",
    "list2 = []\n",
    "for i in range(len(geckojbnew['text'])):\n",
    "    list2.append(se.str.split(\"b'\")[i][1])\n",
    "    \n",
    "    \n",
    "se2 = pd.Series(list2)\n",
    "geckojbnew['cleanedtext'] = se2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "geckojbnew = geckojbnew[geckojbnew['cleanedtext'].str.contains('RT|@|closed|yesterday', case=False)==False]\n",
    "geckojbnew = geckojbnew[geckojbnew['cleanedtext'].str.contains(\"XX'AAPL|XX'ABBV|XX'ABT|XX'ACN|XX'AGN|XX'AIG|XX'ALL|XX'AMGN|XX'AMZN|XX'AXP|XX'BA|XX'BAC|XX'BIIB|XX'BK|XX'BLK|XX'BMY|XX'BRK.B|XX'C|XX'CAT|XX'CELG|XX'CL|XX'CMCSA|XX'COF|XX'COP|XX'COST|XX'CSCO|XX'CVS|XX'CVX|XX'DD|XX'DHR|XX'DIS|XX'DOW|XX'DUK|XX'EMR|XX'EXC|XX'F|XX'FB|XX'FDX|XX'FOX|XX'FOXA|XX'GD|XX'GE|XX'GILD|XX'GM|XX'GOOG|XX'GOOGL|XX'GS|XX'HAL|XX'HD|XX'HON|XX'IBM|XX'INTC|XX'JNJ|XX'JPM|XX'KHC|XX'KMI|XX'KO|XX'LLY|XX'LMT|XX'LOW|XX'MA|XX'MCD|XX'MDLZ|XX'MDT|XX'MET|XX'MMM|XX'MO|XX'MON|XX'MRK|XX'MS|XX'MSFT|XX'NEE|XX'NKE|XX'ORCL|XX'OXY|XX'PCLN|XX'PEP|XX'PFE|XX'PG|XX'PM|XX'PYPL|XX'QCOM|XX'RTN|XX'SBUX|XX'SLB|XX'SO|XX'SPG|XX'T|XX'TGT|XX'TWX|XX'TXN|XX'UNH|XX'UNP|XX'UPS|XX'USB|XX'UTX|XX'V|XX'VZ|XX'WBA|XX'WFC|XX'WMT|XX'XOM\", na=False, case=True)]\n",
    "\n",
    "# bergencapitalnew[bergencapitalnew.text.str.contains('|'.join(sandp100find))]\n",
    "\n",
    "geckojbnew['date'] = geckojbnew['created_at'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "geckojbnew = geckojbnew.sort_values(by='date')\n",
    "geckojbnewextract = geckojbnew.cleanedtext.str.extractall(r\"\"\"(XX'[A-Z]+)\"\"\")\n",
    "geckojbnewextract = geckojbnewextract.unstack()\n",
    "geckojbnew = geckojbnew.join(geckojbnewextract)\n",
    "geckojbnew = geckojbnew.reset_index()\n",
    "\n",
    "\n",
    "for i in range(8, geckojbnew.shape[1]):\n",
    "    geckojbnew.iloc[:,i] = geckojbnew.iloc[:,i].str.replace(\"XX'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojbnew = geckojbnew[(geckojbnew['date']>datetime.date(2017,5,1)) & (geckojbnew['date']<datetime.date(2017,6,18))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_return(X):\n",
    "    count = 0\n",
    "    enum_list = []\n",
    "    first_list = []\n",
    "    for a, b in zip(geckojbnew.iloc[:,7], geckojbnew.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            enum_list.append(np.nan)\n",
    "            first_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% date_data), end_date=(\"%s\"% new_date))\n",
    "            total_sum = my_data.iloc[:,3].sum()\n",
    "#             first_list.append(my_data.iloc[0,3]/total_sum)\n",
    "            enum_list.append((my_data.iloc[-1,10] - my_data.iloc[0,10])/my_data.iloc[0,10])\n",
    "            count += 1\n",
    "#             print(first_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "#     first_list = list(map(float, first_list))\n",
    "    enum_list = list(map(float, enum_list))\n",
    "#     final_list = [z*x for z,x in zip(first_list,enum_list)]\n",
    "    return enum_list\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_return(8))\n",
    "geckojbnew['return_one'] = se.values\n",
    "geckojbnew['return_one'] = pd.to_numeric(geckojbnew['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "right_returns = ['0.018717147','-0.017107014','0.007552824']\n",
    "geckojbnew['return_one'] = right_returns\n",
    "geckojbnew['return_one'] = pd.to_numeric(geckojbnew['return_one'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#geckojbnew.to_csv('geckojbnewcheck.csv') to fix Todays value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# = pd.read_csv('geckojbnewcheck.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "def calc_volatility(X):\n",
    "    count = 0\n",
    "    low_list = []\n",
    "    high_list = []\n",
    "    close_list = []\n",
    "    for a, b in zip(geckojbnew.iloc[:,7], geckojbnew.iloc[:,X]):\n",
    "        if not b in quanstocklist:\n",
    "    #     if b == 'SPY' or b == 'USO' or b == 'GDX' or b == 'AA' or b =='PBR' or b=='ALU' or b == 'STM' or b=='TSL' or b=='EEM' or b == 'XLF' or b=='GSK' or b=='ING' or b=='GLD' or b=='SFUN' or b=='BABA' or b=='GFI' or b=='ARMH' or b=='XX' or b=='MT' or b=='BCS' or b=='TLT' or b=='CSIQ' or b=='GSX' or b=='NUGT' or b=='WFT' or b=='SLV' or b=='UGAZ' or b=='SDRL' or b=='JNK' or b=='TBT' or b=='ASX':\n",
    "            high_list.append(np.nan)\n",
    "            low_list.append(np.nan)\n",
    "            close_list.append(np.nan)\n",
    "            count += 1\n",
    "        else:\n",
    "            date_data = a\n",
    "            stock_name = b\n",
    "            start_date = a - dt.timedelta(days=1)\n",
    "            new_date = a + dt.timedelta(days=1)\n",
    "            my_data = quandl.get(dataset =(\"WIKI/%s\"% stock_name), start_date=(\"%s\"% start_date), end_date=(\"%s\"% new_date))\n",
    "            low_list.append(my_data.iloc[0,2])\n",
    "            high_list.append(my_data.iloc[0,1])\n",
    "            close_list.append(my_data.iloc[0,3])\n",
    "            count += 1\n",
    "#             print(open_list)\n",
    "#         print(count)\n",
    "    #     print(enum_list)\n",
    "    low_list = list(map(float, low_list))\n",
    "    high_list = list(map(float, high_list))\n",
    "    close_list = list(map(float,high_list))\n",
    "    final_list = [0.5*np.log(np.nanmean(np.square((y-x)/z))) for x,y,z in zip(low_list,high_list,close_list)]\n",
    "    return final_list\n",
    "\n",
    "# 0.5*np.log(np.nanmean(np.square((highs-lows)/closes)\n",
    "\n",
    "\n",
    "    \n",
    "se = pd.Series(calc_volatility(9))\n",
    "geckojbnew['prev_day_volatility'] = se.values\n",
    "geckojbnew['prev_day_volatility'] = pd.to_numeric(geckojbnew['prev_day_volatility'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For whatever Reason Quandl was unable to get Previous Day amzn volatility beneath is manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.1318945000190364"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5*np.log(np.nanmean(np.square((57.75-55.33)/55.46)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojbnew.iloc[0,-1] = -3.1318945000190364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojbnew10 = geckojbnew.iloc[:,[5,8,28,29]]\n",
    "\n",
    "# geckojbnew10 = geckojbnew10.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "column_names = ['user', 'Ticker', 'return_one', 'volatility']\n",
    "geckojbnew10.columns = column_names\n",
    "newdfnew2 = geckojbnew10.merge(finviz1, on='Ticker', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>return_one</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>John Benedict</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>-3.131895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>John Benedict</td>\n",
       "      <td>TGT</td>\n",
       "      <td>-0.017107</td>\n",
       "      <td>-3.268376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>John Benedict</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>-2.858846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user Ticker  return_one  volatility\n",
       "272  John Benedict  GOOG   0.018717   -3.131895  \n",
       "273  John Benedict  TGT   -0.017107   -3.268376  \n",
       "274  John Benedict  AMZN   0.007553   -2.858846  "
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geckojbnew10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "def onehotencode(column_name):\n",
    "    global newdfnew2\n",
    "    st = patsy.dmatrix(column_name,\n",
    "                     data=newdfnew2,\n",
    "                     return_type='dataframe')\n",
    "    newdfnew2.drop([column_name], axis=1, inplace=True)\n",
    "    newdfnew2 = newdfnew2.join(st)\n",
    "    newdfnew2.drop(['Intercept'], axis=1, inplace=True)\n",
    "    return newdfnew2\n",
    "\n",
    "newdfnew2 = onehotencode('Sector')\n",
    "newdfnew2 = onehotencode('Industry')\n",
    "newdfnew2 = onehotencode('Country')\n",
    "newdfnew2 = onehotencode('Ticker')\n",
    "newdfnew2 = onehotencode('user')\n",
    "\n",
    "newdfnew2.columns = newdfnew2.columns.map(lambda x: x.replace('[', '_'))\n",
    "newdfnew2.columns = newdfnew2.columns.map(lambda x: x.replace(']', ''))\n",
    "newdfnew2.columns = newdfnew2.columns.map(lambda x: x.replace('.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return_one</th>\n",
       "      <th>volatility</th>\n",
       "      <th>Sector_TTechnology</th>\n",
       "      <th>Industry_TDiscount, Variety Stores</th>\n",
       "      <th>Industry_TInternet Information Providers</th>\n",
       "      <th>Ticker_TGOOG</th>\n",
       "      <th>Ticker_TTGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018717</td>\n",
       "      <td>-3.131895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.017107</td>\n",
       "      <td>-3.268376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007553</td>\n",
       "      <td>-2.858846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   return_one  volatility  Sector_TTechnology  \\\n",
       "0  0.018717   -3.131895    1.0                  \n",
       "1 -0.017107   -3.268376    0.0                  \n",
       "2  0.007553   -2.858846    0.0                  \n",
       "\n",
       "   Industry_TDiscount, Variety Stores  \\\n",
       "0  0.0                                  \n",
       "1  1.0                                  \n",
       "2  0.0                                  \n",
       "\n",
       "   Industry_TInternet Information Providers  Ticker_TGOOG  Ticker_TTGT  \n",
       "0  1.0                                       1.0           0.0          \n",
       "1  0.0                                       0.0           1.0          \n",
       "2  0.0                                       0.0           0.0          "
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdfnew2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_target2= newdfnew2.iloc[:,1]\n",
    "newdfnew2.drop(['return_one'], axis=1, inplace=True)\n",
    "X_data3 = newdfnew2\n",
    "\n",
    "X_data3 = pd.merge(X_data3, X_data, how='outer')\n",
    "\n",
    "X_data3 = X_data3.fillna(0)\n",
    "\n",
    "# xdata3.iloc[[1,2,3],:]\n",
    "\n",
    "list3 = model._Booster.feature_names\n",
    "\n",
    "X_data3 = X_data3[list3]\n",
    "\n",
    "X_data3 = X_data3.iloc[[0,1,2],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatility</th>\n",
       "      <th>Sector_TConsumer Goods</th>\n",
       "      <th>Sector_TFinancial</th>\n",
       "      <th>Sector_TIndustrial Goods</th>\n",
       "      <th>Sector_TServices</th>\n",
       "      <th>Sector_TTechnology</th>\n",
       "      <th>Industry_TApplication Software</th>\n",
       "      <th>Industry_TAuto Manufacturers - Major</th>\n",
       "      <th>Industry_TBeverages - Soft Drinks</th>\n",
       "      <th>Industry_TBusiness Services</th>\n",
       "      <th>Industry_TCopper</th>\n",
       "      <th>Industry_TDiscount, Variety Stores</th>\n",
       "      <th>Industry_TDiversified Machinery</th>\n",
       "      <th>Industry_TElectronic Equipment</th>\n",
       "      <th>Industry_TFarm &amp; Construction Machinery</th>\n",
       "      <th>Industry_TIndependent Oil &amp; Gas</th>\n",
       "      <th>Industry_TIndustrial Equipment Wholesale</th>\n",
       "      <th>Industry_TIndustrial Metals &amp; Minerals</th>\n",
       "      <th>Industry_TInformation Technology Services</th>\n",
       "      <th>Industry_TInternet Information Providers</th>\n",
       "      <th>Industry_TInvestment Brokerage - National</th>\n",
       "      <th>Industry_TMajor Airlines</th>\n",
       "      <th>Industry_TMeat Products</th>\n",
       "      <th>Industry_TMoney Center Banks</th>\n",
       "      <th>Industry_TProperty &amp; Casualty Insurance</th>\n",
       "      <th>Industry_TRestaurants</th>\n",
       "      <th>Industry_TSecurity &amp; Protection Services</th>\n",
       "      <th>Industry_TSpecialty Chemicals</th>\n",
       "      <th>Industry_TSpecialty Retail, Other</th>\n",
       "      <th>Industry_TTelecom Services - Domestic</th>\n",
       "      <th>Industry_TTextile - Apparel Footwear &amp; Accessories</th>\n",
       "      <th>Industry_TWireless Communications</th>\n",
       "      <th>Country_TUnited Kingdom</th>\n",
       "      <th>Ticker_TAIG</th>\n",
       "      <th>Ticker_TASCMA</th>\n",
       "      <th>Ticker_TCAT</th>\n",
       "      <th>Ticker_TCHK</th>\n",
       "      <th>Ticker_TCOH</th>\n",
       "      <th>Ticker_TCSLT</th>\n",
       "      <th>Ticker_TCVO</th>\n",
       "      <th>Ticker_TFAST</th>\n",
       "      <th>Ticker_TFB</th>\n",
       "      <th>Ticker_TFCX</th>\n",
       "      <th>Ticker_TFDX</th>\n",
       "      <th>Ticker_TGE</th>\n",
       "      <th>Ticker_TGM</th>\n",
       "      <th>Ticker_TGOOG</th>\n",
       "      <th>Ticker_TGS</th>\n",
       "      <th>Ticker_TIBM</th>\n",
       "      <th>Ticker_TJPM</th>\n",
       "      <th>Ticker_TKRO</th>\n",
       "      <th>Ticker_TMCD</th>\n",
       "      <th>Ticker_TMS</th>\n",
       "      <th>Ticker_TPEP</th>\n",
       "      <th>Ticker_TT</th>\n",
       "      <th>Ticker_TTAHO</th>\n",
       "      <th>Ticker_TTRIP</th>\n",
       "      <th>Ticker_TTSCO</th>\n",
       "      <th>Ticker_TTSN</th>\n",
       "      <th>Ticker_TTWTR</th>\n",
       "      <th>Ticker_TTXRH</th>\n",
       "      <th>Ticker_TUAL</th>\n",
       "      <th>Ticker_TVOD</th>\n",
       "      <th>Ticker_TWFC</th>\n",
       "      <th>Ticker_TWMT</th>\n",
       "      <th>user_Ticahn</th>\n",
       "      <th>user_Tlexvandam</th>\n",
       "      <th>user_Tpeterw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.131895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.268376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.858846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   volatility  Sector_TConsumer Goods  Sector_TFinancial  \\\n",
       "0 -3.131895    0.0                     0.0                 \n",
       "1 -3.268376    0.0                     0.0                 \n",
       "2 -2.858846    0.0                     0.0                 \n",
       "\n",
       "   Sector_TIndustrial Goods  Sector_TServices  Sector_TTechnology  \\\n",
       "0  0.0                       0.0               1.0                  \n",
       "1  0.0                       0.0               0.0                  \n",
       "2  0.0                       0.0               0.0                  \n",
       "\n",
       "   Industry_TApplication Software  Industry_TAuto Manufacturers - Major  \\\n",
       "0  0.0                             0.0                                    \n",
       "1  0.0                             0.0                                    \n",
       "2  0.0                             0.0                                    \n",
       "\n",
       "   Industry_TBeverages - Soft Drinks  Industry_TBusiness Services  \\\n",
       "0  0.0                                0.0                           \n",
       "1  0.0                                0.0                           \n",
       "2  0.0                                0.0                           \n",
       "\n",
       "   Industry_TCopper  Industry_TDiscount, Variety Stores  \\\n",
       "0  0.0               0.0                                  \n",
       "1  0.0               1.0                                  \n",
       "2  0.0               0.0                                  \n",
       "\n",
       "   Industry_TDiversified Machinery  Industry_TElectronic Equipment  \\\n",
       "0  0.0                              0.0                              \n",
       "1  0.0                              0.0                              \n",
       "2  0.0                              0.0                              \n",
       "\n",
       "   Industry_TFarm & Construction Machinery  Industry_TIndependent Oil & Gas  \\\n",
       "0  0.0                                      0.0                               \n",
       "1  0.0                                      0.0                               \n",
       "2  0.0                                      0.0                               \n",
       "\n",
       "   Industry_TIndustrial Equipment Wholesale  \\\n",
       "0  0.0                                        \n",
       "1  0.0                                        \n",
       "2  0.0                                        \n",
       "\n",
       "   Industry_TIndustrial Metals & Minerals  \\\n",
       "0  0.0                                      \n",
       "1  0.0                                      \n",
       "2  0.0                                      \n",
       "\n",
       "   Industry_TInformation Technology Services  \\\n",
       "0  0.0                                         \n",
       "1  0.0                                         \n",
       "2  0.0                                         \n",
       "\n",
       "   Industry_TInternet Information Providers  \\\n",
       "0  1.0                                        \n",
       "1  0.0                                        \n",
       "2  0.0                                        \n",
       "\n",
       "   Industry_TInvestment Brokerage - National  Industry_TMajor Airlines  \\\n",
       "0  0.0                                        0.0                        \n",
       "1  0.0                                        0.0                        \n",
       "2  0.0                                        0.0                        \n",
       "\n",
       "   Industry_TMeat Products  Industry_TMoney Center Banks  \\\n",
       "0  0.0                      0.0                            \n",
       "1  0.0                      0.0                            \n",
       "2  0.0                      0.0                            \n",
       "\n",
       "   Industry_TProperty & Casualty Insurance  Industry_TRestaurants  \\\n",
       "0  0.0                                      0.0                     \n",
       "1  0.0                                      0.0                     \n",
       "2  0.0                                      0.0                     \n",
       "\n",
       "   Industry_TSecurity & Protection Services  Industry_TSpecialty Chemicals  \\\n",
       "0  0.0                                       0.0                             \n",
       "1  0.0                                       0.0                             \n",
       "2  0.0                                       0.0                             \n",
       "\n",
       "   Industry_TSpecialty Retail, Other  Industry_TTelecom Services - Domestic  \\\n",
       "0  0.0                                0.0                                     \n",
       "1  0.0                                0.0                                     \n",
       "2  0.0                                0.0                                     \n",
       "\n",
       "   Industry_TTextile - Apparel Footwear & Accessories  \\\n",
       "0  0.0                                                  \n",
       "1  0.0                                                  \n",
       "2  0.0                                                  \n",
       "\n",
       "   Industry_TWireless Communications  Country_TUnited Kingdom  Ticker_TAIG  \\\n",
       "0  0.0                                0.0                      0.0           \n",
       "1  0.0                                0.0                      0.0           \n",
       "2  0.0                                0.0                      0.0           \n",
       "\n",
       "   Ticker_TASCMA  Ticker_TCAT  Ticker_TCHK  Ticker_TCOH  Ticker_TCSLT  \\\n",
       "0  0.0            0.0          0.0          0.0          0.0            \n",
       "1  0.0            0.0          0.0          0.0          0.0            \n",
       "2  0.0            0.0          0.0          0.0          0.0            \n",
       "\n",
       "   Ticker_TCVO  Ticker_TFAST  Ticker_TFB  Ticker_TFCX  Ticker_TFDX  \\\n",
       "0  0.0          0.0           0.0         0.0          0.0           \n",
       "1  0.0          0.0           0.0         0.0          0.0           \n",
       "2  0.0          0.0           0.0         0.0          0.0           \n",
       "\n",
       "   Ticker_TGE  Ticker_TGM  Ticker_TGOOG  Ticker_TGS  Ticker_TIBM  Ticker_TJPM  \\\n",
       "0  0.0         0.0         1.0           0.0         0.0          0.0           \n",
       "1  0.0         0.0         0.0           0.0         0.0          0.0           \n",
       "2  0.0         0.0         0.0           0.0         0.0          0.0           \n",
       "\n",
       "   Ticker_TKRO  Ticker_TMCD  Ticker_TMS  Ticker_TPEP  Ticker_TT  Ticker_TTAHO  \\\n",
       "0  0.0          0.0          0.0         0.0          0.0        0.0            \n",
       "1  0.0          0.0          0.0         0.0          0.0        0.0            \n",
       "2  0.0          0.0          0.0         0.0          0.0        0.0            \n",
       "\n",
       "   Ticker_TTRIP  Ticker_TTSCO  Ticker_TTSN  Ticker_TTWTR  Ticker_TTXRH  \\\n",
       "0  0.0           0.0           0.0          0.0           0.0            \n",
       "1  0.0           0.0           0.0          0.0           0.0            \n",
       "2  0.0           0.0           0.0          0.0           0.0            \n",
       "\n",
       "   Ticker_TUAL  Ticker_TVOD  Ticker_TWFC  Ticker_TWMT  user_Ticahn  \\\n",
       "0  0.0          0.0          0.0          0.0          0.0           \n",
       "1  0.0          0.0          0.0          0.0          0.0           \n",
       "2  0.0          0.0          0.0          0.0          0.0           \n",
       "\n",
       "   user_Tlexvandam  user_Tpeterw  \n",
       "0  0.0              0.0           \n",
       "1  0.0              0.0           \n",
       "2  0.0              0.0           "
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojbpredict = model.predict(X_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojbfinal = geckojbnew.iloc[:,[7,4,5,8,28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xgboost._booster.dump (TRANSFER TO R and perform rest of predictions there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>(0, 0)</th>\n",
       "      <th>return_one</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>b'Come on $GOOG buy $SFM'</td>\n",
       "      <td>John Benedict</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>-0.010297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>b'For value managers there are very little areas to invest in outside Energy and Retail.  They must buy these names right?  $TGT $RIG $KR $WMT'</td>\n",
       "      <td>John Benedict</td>\n",
       "      <td>TGT</td>\n",
       "      <td>-0.017107</td>\n",
       "      <td>0.003892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>b'$AMZN is a cult stock. So many variable they must get right to pull off this $WFM deal but everyone just accepts they will.'</td>\n",
       "      <td>John Benedict</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>0.025486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  \\\n",
       "272  2017-06-16   \n",
       "273  2017-06-16   \n",
       "274  2017-06-16   \n",
       "\n",
       "                                                                                                                                                text  \\\n",
       "272  b'Come on $GOOG buy $SFM'                                                                                                                         \n",
       "273  b'For value managers there are very little areas to invest in outside Energy and Retail.  They must buy these names right?  $TGT $RIG $KR $WMT'   \n",
       "274  b'$AMZN is a cult stock. So many variable they must get right to pull off this $WFM deal but everyone just accepts they will.'                    \n",
       "\n",
       "              user (0, 0)  return_one  prediction  \n",
       "272  John Benedict  GOOG   0.018717   -0.010297    \n",
       "273  John Benedict  TGT   -0.017107    0.003892    \n",
       "274  John Benedict  AMZN   0.007553    0.025486    "
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geckojbfinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelcarrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "geckojbfinal['prediction'] = geckojbpredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names2 = ['Date', 'Tweet', 'User','Ticker', 'Actual_Return', 'Prediction']\n",
    "# geckojbfinal['prediction'] = geckojbpredict\n",
    "geckojbfinal.columns = column_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geckojbfinal.to_csv('geckojbfinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rest of Predictions in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "path = 'sendtor.feather'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>cleanedtext</th>\n",
       "      <th>date</th>\n",
       "      <th>(0, 0)</th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(0, 2)</th>\n",
       "      <th>(0, 3)</th>\n",
       "      <th>(0, 4)</th>\n",
       "      <th>(0, 5)</th>\n",
       "      <th>(0, 6)</th>\n",
       "      <th>(0, 7)</th>\n",
       "      <th>(0, 8)</th>\n",
       "      <th>(0, 9)</th>\n",
       "      <th>(0, 10)</th>\n",
       "      <th>(0, 11)</th>\n",
       "      <th>(0, 12)</th>\n",
       "      <th>(0, 13)</th>\n",
       "      <th>(0, 14)</th>\n",
       "      <th>(0, 15)</th>\n",
       "      <th>(0, 16)</th>\n",
       "      <th>(0, 17)</th>\n",
       "      <th>(0, 18)</th>\n",
       "      <th>(0, 19)</th>\n",
       "      <th>return_one</th>\n",
       "      <th>prev_day_volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>186</td>\n",
       "      <td>5949c609ea2a7c59b3fe4cfb</td>\n",
       "      <td>2017-06-16 14:28:41</td>\n",
       "      <td>875721798847000576</td>\n",
       "      <td>b'Come on $GOOG buy $SFM'</td>\n",
       "      <td>John Benedict</td>\n",
       "      <td>Come on XX'GOOG buy XX'SFM'</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>SFM</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>-3.131895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2782</td>\n",
       "      <td>5949c609ea2a7c59b3fe571f</td>\n",
       "      <td>2017-06-16 14:21:11</td>\n",
       "      <td>875719911926005760</td>\n",
       "      <td>b'For value managers there are very little areas to invest in outside Energy and Retail.  They must buy these names right?  $TGT $RIG $KR $WMT'</td>\n",
       "      <td>John Benedict</td>\n",
       "      <td>For value managers there are very little areas to invest in outside Energy and Retail.  They must buy these names right?  XX'TGT XX'RIG XX'KR XX'WMT'</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>TGT</td>\n",
       "      <td>RIG</td>\n",
       "      <td>KR</td>\n",
       "      <td>WMT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.017107</td>\n",
       "      <td>-3.268376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2476</td>\n",
       "      <td>5949c609ea2a7c59b3fe55ed</td>\n",
       "      <td>2017-06-16 14:22:37</td>\n",
       "      <td>875720273089232897</td>\n",
       "      <td>b'$AMZN is a cult stock. So many variable they must get right to pull off this $WFM deal but everyone just accepts they will.'</td>\n",
       "      <td>John Benedict</td>\n",
       "      <td>XX'AMZN is a cult stock. So many variable they must get right to pull off this XX'WFM deal but everyone just accepts they will.'</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>WFM</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>-2.858846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                       _id           created_at                  id  \\\n",
       "272  186    5949c609ea2a7c59b3fe4cfb  2017-06-16 14:28:41  875721798847000576   \n",
       "273  2782   5949c609ea2a7c59b3fe571f  2017-06-16 14:21:11  875719911926005760   \n",
       "274  2476   5949c609ea2a7c59b3fe55ed  2017-06-16 14:22:37  875720273089232897   \n",
       "\n",
       "                                                                                                                                                text  \\\n",
       "272  b'Come on $GOOG buy $SFM'                                                                                                                         \n",
       "273  b'For value managers there are very little areas to invest in outside Energy and Retail.  They must buy these names right?  $TGT $RIG $KR $WMT'   \n",
       "274  b'$AMZN is a cult stock. So many variable they must get right to pull off this $WFM deal but everyone just accepts they will.'                    \n",
       "\n",
       "              user  \\\n",
       "272  John Benedict   \n",
       "273  John Benedict   \n",
       "274  John Benedict   \n",
       "\n",
       "                                                                                                                                               cleanedtext  \\\n",
       "272  Come on XX'GOOG buy XX'SFM'                                                                                                                             \n",
       "273  For value managers there are very little areas to invest in outside Energy and Retail.  They must buy these names right?  XX'TGT XX'RIG XX'KR XX'WMT'   \n",
       "274  XX'AMZN is a cult stock. So many variable they must get right to pull off this XX'WFM deal but everyone just accepts they will.'                        \n",
       "\n",
       "           date (0, 0) (0, 1) (0, 2) (0, 3) (0, 4) (0, 5) (0, 6) (0, 7)  \\\n",
       "272  2017-06-16  GOOG   SFM    None   None   None   None   None   None    \n",
       "273  2017-06-16  TGT    RIG    KR     WMT    None   None   None   None    \n",
       "274  2017-06-16  AMZN   WFM    None   None   None   None   None   None    \n",
       "\n",
       "    (0, 8) (0, 9) (0, 10) (0, 11) (0, 12) (0, 13) (0, 14) (0, 15) (0, 16)  \\\n",
       "272  None   None   None    None    None    None    None    None    None     \n",
       "273  None   None   None    None    None    None    None    None    None     \n",
       "274  None   None   None    None    None    None    None    None    None     \n",
       "\n",
       "    (0, 17) (0, 18) (0, 19)  return_one  prev_day_volatility  \n",
       "272  None    None    None    0.018717   -3.131895             \n",
       "273  None    None    None   -0.017107   -3.268376             \n",
       "274  None    None    None    0.007553   -2.858846             "
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geckojbnew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
