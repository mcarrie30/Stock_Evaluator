{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "import gensim\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.externals import joblib\n",
    "import csv\n",
    "import tweepy\n",
    "import cnfg\n",
    "import datetime\n",
    "import quandl\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "quandl.ApiConfig.api_key = 'znHHs6G4PW7wzMwGkpTT' \n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "# pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "# pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import cnfg\n",
    "import pandas as pd\n",
    "config = cnfg.load(\"./.twitter_config\")\n",
    "\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(config[\"consumer_key\"],\n",
    "                           config[\"consumer_secret\"])\n",
    "\n",
    "auth.set_access_token(config[\"access_token\"],\n",
    "                      config[\"access_token_secret\"])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def get_all_tweets(screen_name):\n",
    "\n",
    "    api = tweepy.API(auth)\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(\"getting tweets before %s\" % (oldest))\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    \n",
    "    with open('%s_tweets2.csv' % screen_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "        writer.writerows(outtweets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 796108410282475519\n",
      "...397 tweets downloaded so far\n",
      "getting tweets before 784543523664265216\n",
      "...596 tweets downloaded so far\n",
      "getting tweets before 720209281086136320\n",
      "...795 tweets downloaded so far\n",
      "getting tweets before 635899826660634624\n",
      "...992 tweets downloaded so far\n",
      "getting tweets before 581190229299761151\n",
      "...1192 tweets downloaded so far\n",
      "getting tweets before 554700699096068095\n",
      "...1386 tweets downloaded so far\n",
      "getting tweets before 534763294125719551\n",
      "...1585 tweets downloaded so far\n",
      "getting tweets before 499291071340630015\n",
      "...1783 tweets downloaded so far\n",
      "getting tweets before 459073663925764095\n",
      "...1982 tweets downloaded so far\n",
      "getting tweets before 395980817874178047\n",
      "...2182 tweets downloaded so far\n",
      "getting tweets before 367844042295738367\n",
      "...2380 tweets downloaded so far\n",
      "getting tweets before 332668127093604352\n",
      "...2580 tweets downloaded so far\n",
      "getting tweets before 321644206533783551\n",
      "...2780 tweets downloaded so far\n",
      "getting tweets before 304333922542690303\n",
      "...2980 tweets downloaded so far\n",
      "getting tweets before 286921742398660607\n",
      "...3179 tweets downloaded so far\n",
      "getting tweets before 278511227687276543\n",
      "...3206 tweets downloaded so far\n",
      "getting tweets before 278196597496631295\n",
      "...3206 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"bergencapital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bergencapital2 = pd.read_csv('bergencapital_tweets2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x119ac6120>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.newstocks\n",
    "\n",
    "records = json.loads(bergencapital2.T.to_json()).values()\n",
    "db.bergencapital2.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 875139832091205632\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 872836839782047743\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 870570807315050495\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 867211405728010240\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 864839679094292479\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 864183030251872255\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 862354706714120191\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 859954211789787135\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 858125208384819199\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 857241589583798271\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 856507669133180927\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 855029630524248063\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 853959230964998143\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 851909956555034623\n",
      "...2999 tweets downloaded so far\n",
      "getting tweets before 850163441813798912\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 849297671034740735\n",
      "...3221 tweets downloaded so far\n",
      "getting tweets before 849101287001948161\n",
      "...3221 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"mark_dow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "markdownew = pd.read_csv('mark_dow_tweets2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11b3f9ea0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.newstocks\n",
    "\n",
    "records = json.loads(markdownew.T.to_json()).values()\n",
    "db.markdownew.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 796234882615807999\n",
      "...383 tweets downloaded so far\n",
      "getting tweets before 760526879338143743\n",
      "...582 tweets downloaded so far\n",
      "getting tweets before 684005293278146559\n",
      "...782 tweets downloaded so far\n",
      "getting tweets before 639106236936527871\n",
      "...982 tweets downloaded so far\n",
      "getting tweets before 370208180711600128\n",
      "...1182 tweets downloaded so far\n",
      "getting tweets before 281422460107235332\n",
      "...1382 tweets downloaded so far\n",
      "getting tweets before 212923753376661503\n",
      "...1580 tweets downloaded so far\n",
      "getting tweets before 193368984085733376\n",
      "...1778 tweets downloaded so far\n",
      "getting tweets before 169521752018391040\n",
      "...1978 tweets downloaded so far\n",
      "getting tweets before 141987707625807871\n",
      "...2178 tweets downloaded so far\n",
      "getting tweets before 116164515334336511\n",
      "...2377 tweets downloaded so far\n",
      "getting tweets before 98094515352641535\n",
      "...2577 tweets downloaded so far\n",
      "getting tweets before 73119222712123391\n",
      "...2777 tweets downloaded so far\n",
      "getting tweets before 52831119246237695\n",
      "...2976 tweets downloaded so far\n",
      "getting tweets before 24935660989190143\n",
      "...3176 tweets downloaded so far\n",
      "getting tweets before 8709579089125375\n",
      "...3215 tweets downloaded so far\n",
      "getting tweets before 4712993635958783\n",
      "...3215 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets('geckojb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "geckojbnew = pd.read_csv('geckojb_tweets2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11aa3b5e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.newstocks\n",
    "\n",
    "records = json.loads(geckojbnew.T.to_json()).values()\n",
    "db.geckojbnew.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_all_tweets('Scaramucci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_all_tweets('KeithMcCullough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_all_tweets('WhitneyTilson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_all_tweets('georgesoros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_all_tweets('TomSteyer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_all_tweets('cimmerian999')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
