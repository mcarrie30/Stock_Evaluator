{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "# pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import cnfg\n",
    "import pandas as pd\n",
    "config = cnfg.load(\"./.twitter_config\")\n",
    "\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(config[\"consumer_key\"],\n",
    "                           config[\"consumer_secret\"])\n",
    "\n",
    "auth.set_access_token(config[\"access_token\"],\n",
    "                      config[\"access_token_secret\"])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def get_all_tweets(screen_name):\n",
    "\n",
    "    api = tweepy.API(auth)\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(\"getting tweets before %s\" % (oldest))\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    \n",
    "    with open('%s_tweets.csv' % screen_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "        writer.writerows(outtweets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 847552003874148351\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 822091939373838336\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 796712713225375743\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 774949667821854719\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 755187861339639811\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 734753342057000959\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 710099358453084160\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 692355399219961856\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 674233149426044929\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 659828558878138367\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 639800095223877631\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 624570492381323263\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 614158341108047874\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 605813969417179135\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 591236807599194111\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 580818274168004609\n",
      "...3223 tweets downloaded so far\n",
      "getting tweets before 580731204695158784\n",
      "...3223 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"VolumePrintcess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('VolumePrintcess_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x114594168>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.stocks.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOCKS TO TRADE ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 868172481517031424\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 865302984472899583\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 862313218047389695\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 857370444193816576\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 853992896172892163\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 849263903095836672\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 845653216973000704\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 839304499881787392\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 835125697249218559\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 831892357964460031\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 829125775123165183\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 826445482784391168\n",
      "...2598 tweets downloaded so far\n",
      "getting tweets before 822919775995228160\n",
      "...2797 tweets downloaded so far\n",
      "getting tweets before 821446749122416640\n",
      "...2996 tweets downloaded so far\n",
      "getting tweets before 817410421779005439\n",
      "...3195 tweets downloaded so far\n",
      "getting tweets before 810928155091435519\n",
      "...3195 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"StocksToTrade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('StocksToTrade_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1145846c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.stockstotrade.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CandidBanter Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 827514417218719745\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 781113159264251903\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 747791275399602175\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 702694671542169599\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 680054897899749375\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 663546516481531904\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 650478210950434815\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 632016300580061184\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 617752718321451007\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 594124380990353409\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 577098347745411071\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 566087662809792511\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 552995223182540799\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 541646846523740160\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 527278547703177215\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 512797233985495040\n",
      "...3237 tweets downloaded so far\n",
      "getting tweets before 510419968341463039\n",
      "...3237 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"candidbanter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('candidbanter_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x118ef6dc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.candidbanter.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriggeroftheDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 871616340926369791\n",
      "...399 tweets downloaded so far\n",
      "getting tweets before 868249144221200384\n",
      "...599 tweets downloaded so far\n",
      "getting tweets before 864595072809144320\n",
      "...799 tweets downloaded so far\n",
      "getting tweets before 862028166621167616\n",
      "...998 tweets downloaded so far\n",
      "getting tweets before 858857256821170179\n",
      "...1198 tweets downloaded so far\n",
      "getting tweets before 855882659674849280\n",
      "...1396 tweets downloaded so far\n",
      "getting tweets before 851790705001418753\n",
      "...1591 tweets downloaded so far\n",
      "getting tweets before 848181921939062789\n",
      "...1791 tweets downloaded so far\n",
      "getting tweets before 844678851078885376\n",
      "...1986 tweets downloaded so far\n",
      "getting tweets before 841477739081265151\n",
      "...2183 tweets downloaded so far\n",
      "getting tweets before 838639035061006336\n",
      "...2381 tweets downloaded so far\n",
      "getting tweets before 835347344916942847\n",
      "...2580 tweets downloaded so far\n",
      "getting tweets before 832402944574312447\n",
      "...2779 tweets downloaded so far\n",
      "getting tweets before 829517938545790975\n",
      "...2978 tweets downloaded so far\n",
      "getting tweets before 826620001582997504\n",
      "...3177 tweets downloaded so far\n",
      "getting tweets before 823599942090575871\n",
      "...3215 tweets downloaded so far\n",
      "getting tweets before 822739279550025728\n",
      "...3215 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"triggeroftheday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('triggeroftheday_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x119322678>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.triggeroftheday.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carlcicahn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 459417628311035903\n",
      "...321 tweets downloaded so far\n",
      "getting tweets before 347739201191702527\n",
      "...321 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"carl_c_icahn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('carl_c_icahn_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x118b2fd80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.icahn.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 839714513985368063\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 802108390679998463\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 768691527208071167\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 728506866209198079\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 689107126187331584\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 655014552892002303\n",
      "...1399 tweets downloaded so far\n",
      "getting tweets before 623850061567524863\n",
      "...1595 tweets downloaded so far\n",
      "getting tweets before 578484011561033727\n",
      "...1790 tweets downloaded so far\n",
      "getting tweets before 552416733278273535\n",
      "...1985 tweets downloaded so far\n",
      "getting tweets before 523451998394646527\n",
      "...2183 tweets downloaded so far\n",
      "getting tweets before 428842513407832063\n",
      "...2383 tweets downloaded so far\n",
      "getting tweets before 363227918899486720\n",
      "...2583 tweets downloaded so far\n",
      "getting tweets before 311377345565052927\n",
      "...2783 tweets downloaded so far\n",
      "getting tweets before 276457635807641599\n",
      "...2983 tweets downloaded so far\n",
      "getting tweets before 235256722636296192\n",
      "...3183 tweets downloaded so far\n",
      "getting tweets before 185357687272382463\n",
      "...3193 tweets downloaded so far\n",
      "getting tweets before 184163246595522559\n",
      "...3193 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"PeterCWarren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('PeterCWarren_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11a564870>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.peterw.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BergenCapital**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 795399786643988483\n",
      "...398 tweets downloaded so far\n",
      "getting tweets before 784173800036438015\n",
      "...597 tweets downloaded so far\n",
      "getting tweets before 707328486302687231\n",
      "...796 tweets downloaded so far\n",
      "getting tweets before 635802905040318463\n",
      "...992 tweets downloaded so far\n",
      "getting tweets before 578514706253627391\n",
      "...1192 tweets downloaded so far\n",
      "getting tweets before 553699526536867839\n",
      "...1386 tweets downloaded so far\n",
      "getting tweets before 533637082871111679\n",
      "...1585 tweets downloaded so far\n",
      "getting tweets before 498989121524994048\n",
      "...1783 tweets downloaded so far\n",
      "getting tweets before 458667080133660671\n",
      "...1982 tweets downloaded so far\n",
      "getting tweets before 394877459708903423\n",
      "...2182 tweets downloaded so far\n",
      "getting tweets before 367766411688833023\n",
      "...2380 tweets downloaded so far\n",
      "getting tweets before 332109228565225471\n",
      "...2580 tweets downloaded so far\n",
      "getting tweets before 321580808630595583\n",
      "...2780 tweets downloaded so far\n",
      "getting tweets before 304312633513897984\n",
      "...2980 tweets downloaded so far\n",
      "getting tweets before 286870761321402368\n",
      "...3179 tweets downloaded so far\n",
      "getting tweets before 278504257961983999\n",
      "...3201 tweets downloaded so far\n",
      "getting tweets before 278196597496631295\n",
      "...3201 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"BergenCapital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('bergencapital_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x116d75c60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.bergencapital.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mark Dow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 874290920329330691\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 871766963818770431\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 869603430138040319\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 865553783442391039\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 864516518750543871\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 863249546352107520\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 861612207011807231\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 859401098687168511\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 857621665278181376\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 856908370527174657\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 855439855236521984\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 854380513556963327\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 852571834465648639\n",
      "...2799 tweets downloaded so far\n",
      "getting tweets before 851494985908146175\n",
      "...2999 tweets downloaded so far\n",
      "getting tweets before 849969984298115072\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 847929741453733887\n",
      "...3228 tweets downloaded so far\n",
      "getting tweets before 847841859372163071\n",
      "...3228 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"mark_dow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('mark_dow_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11b64c288>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.markdow.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Lexvandam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 784340026939219967\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 732565564711968767\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 635894375801843711\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 591188656460853248\n",
      "...998 tweets downloaded so far\n",
      "getting tweets before 530308033264762879\n",
      "...1197 tweets downloaded so far\n",
      "getting tweets before 453535716627464191\n",
      "...1394 tweets downloaded so far\n",
      "getting tweets before 398820630763552768\n",
      "...1590 tweets downloaded so far\n",
      "getting tweets before 316204383664746495\n",
      "...1785 tweets downloaded so far\n",
      "getting tweets before 266910712083927039\n",
      "...1985 tweets downloaded so far\n",
      "getting tweets before 235433818935422975\n",
      "...2185 tweets downloaded so far\n",
      "getting tweets before 219713070791016447\n",
      "...2384 tweets downloaded so far\n",
      "getting tweets before 215690248481554433\n",
      "...2584 tweets downloaded so far\n",
      "getting tweets before 214414746278051840\n",
      "...2783 tweets downloaded so far\n",
      "getting tweets before 212798763624960002\n",
      "...2983 tweets downloaded so far\n",
      "getting tweets before 208093226576519167\n",
      "...3183 tweets downloaded so far\n",
      "getting tweets before 187549502117384193\n",
      "...3193 tweets downloaded so far\n",
      "getting tweets before 187443919297060864\n",
      "...3193 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets(\"lexvandam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('lexvandam_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11a2ac870>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.lexvandam.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIM SEYMOUR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 865268261381963775\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 856497524726747136\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 847112402428723199\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 842037589855072257\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 836586461357035521\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 830060507289751552\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 821575340959141888\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 810905757214535680\n",
      "...1797 tweets downloaded so far\n",
      "getting tweets before 801491078784360447\n",
      "...1997 tweets downloaded so far\n",
      "getting tweets before 795992368864526335\n",
      "...2197 tweets downloaded so far\n",
      "getting tweets before 790543159310835711\n",
      "...2396 tweets downloaded so far\n",
      "getting tweets before 782975543000063999\n",
      "...2596 tweets downloaded so far\n",
      "getting tweets before 775718573431988223\n",
      "...2796 tweets downloaded so far\n",
      "getting tweets before 765556764540538879\n",
      "...2996 tweets downloaded so far\n",
      "getting tweets before 756496197716676607\n",
      "...3196 tweets downloaded so far\n",
      "getting tweets before 748892898079412224\n",
      "...3197 tweets downloaded so far\n",
      "getting tweets before 748891108164378623\n",
      "...3197 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets('timseymour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('timseymour_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11b597e58>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.timseymour.insert_many(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gecko**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 796234122419195903\n",
      "...382 tweets downloaded so far\n",
      "getting tweets before 760246190692786175\n",
      "...582 tweets downloaded so far\n",
      "getting tweets before 679688579241529343\n",
      "...782 tweets downloaded so far\n",
      "getting tweets before 638876552600530946\n",
      "...982 tweets downloaded so far\n",
      "getting tweets before 369846769695219711\n",
      "...1182 tweets downloaded so far\n",
      "getting tweets before 281147839982215167\n",
      "...1382 tweets downloaded so far\n",
      "getting tweets before 212733649836187648\n",
      "...1580 tweets downloaded so far\n",
      "getting tweets before 193368736277872639\n",
      "...1778 tweets downloaded so far\n",
      "getting tweets before 169456953163137024\n",
      "...1978 tweets downloaded so far\n",
      "getting tweets before 141987077054136319\n",
      "...2178 tweets downloaded so far\n",
      "getting tweets before 116160055228891135\n",
      "...2377 tweets downloaded so far\n",
      "getting tweets before 96776334143012863\n",
      "...2577 tweets downloaded so far\n",
      "getting tweets before 72729845578211327\n",
      "...2777 tweets downloaded so far\n",
      "getting tweets before 52811469506617343\n",
      "...2976 tweets downloaded so far\n",
      "getting tweets before 24894189145686015\n",
      "...3176 tweets downloaded so far\n",
      "getting tweets before 7508266825285631\n",
      "...3204 tweets downloaded so far\n",
      "getting tweets before 4977981978050560\n",
      "...3213 tweets downloaded so far\n",
      "getting tweets before 4712993635958783\n",
      "...3213 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "get_all_tweets('geckojb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('geckojb_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11b973318>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345)\n",
    "db = client.stocks\n",
    "\n",
    "records = json.loads(df.T.to_json()).values()\n",
    "db.geckojb.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##LOOKING AT ALPHA"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
